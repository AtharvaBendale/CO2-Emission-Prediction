{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(128)\n",
    "np.random.seed(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './playground-series-s3e20'\n",
    "# Load files\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "samplesubmission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "\n",
    "# Preview train dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesubmission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape, samplesubmission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test.shape[0]) / (train.shape[0] + test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['location'] = [str(x) + '_' + str(y) for x, y in zip(train.latitude, train.longitude)]\n",
    "\n",
    "# Filter based on one location\n",
    "example_loc = train[train.location == '-0.51_29.29']\n",
    "\n",
    "# Calculate rolling mean for SulphurDioxide_SO2_column_number_density_amf with a window of 2 weeks\n",
    "rolling_mean = example_loc['SulphurDioxide_SO2_column_number_density_amf'].rolling(window = 2).mean()\n",
    "\n",
    "# Visualise rolling mean\n",
    "plt.figure(figsize = (15, 7))\n",
    "rolling_mean.plot()\n",
    "plt.title('Rolling mean with a window of 2 weeks for SulphurDioxide_SO2_column_number_density_amf', y = 1.02, fontsize = 15)\n",
    "plt.xlabel('week', y = 1.05, fontsize = 13)\n",
    "plt.ylabel('SulphurDioxide_SO2_column_number_density_amf', x = 1.05, fontsize = 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roll_mean = train.sort_values(by = ['location', 'year', 'week_no']).groupby(['location'])[train.columns[5:].tolist()].rolling(window = 2).mean().reset_index()\n",
    "train_roll_mean.drop(['level_1', 'emission', 'location'], axis = 1, inplace = True)\n",
    "train_roll_mean.columns = [col + '_roll_mean' for col in train_roll_mean.columns]\n",
    "\n",
    "# Feature engineering test\n",
    "test.latitude, test.longitude = round(test.latitude, 2), round(test.longitude, 2)\n",
    "test['location'] = [str(x) + '_' + str(y) for x, y in zip(test.latitude, test.longitude)]\n",
    "test_roll_mean = test.sort_values(by = ['location', 'year', 'week_no']).groupby(['location'])[test.columns[5:].tolist()].rolling(window = 2).mean().reset_index()\n",
    "test_roll_mean.drop(['level_1', 'location'], axis = 1, inplace = True)\n",
    "test_roll_mean.columns =  [col + '_roll_mean' for col in test_roll_mean.columns]\n",
    "test_roll_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eng = train.sort_values(by = ['location', 'year', 'week_no'], ignore_index = True).merge(train_roll_mean, how = 'left',\n",
    "                                                                                               left_index=True, right_index=True)\n",
    "# Test\n",
    "test_eng = test.sort_values(by = ['location', 'year', 'week_no'], ignore_index = True).merge(test_roll_mean, how = 'left',\n",
    "                                                                                               left_index=True, right_index=True)\n",
    "# Preview engineered test set\n",
    "test_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_eng.drop(['ID_LAT_LON_YEAR_WEEK', 'location', 'emission'], axis = 1).fillna(0)\n",
    "y = train_eng.emission\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)\n",
    "\n",
    "# Instantiating the model\n",
    "clf = RandomForestRegressor(random_state = SEED, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Measuring the accuracy of the model\n",
    "print(f'RMSE Score: {mean_squared_error(y_test, y_pred, squared=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_errors = X_test.copy()\n",
    "pred_errors['emission'] = y_test\n",
    "pred_errors['prediction'] = y_pred\n",
    "pred_errors['error'] = abs(pred_errors.prediction - pred_errors.emission)\n",
    "pred_errors = pred_errors[['latitude',\t'longitude',\t'year',\t'week_no', 'emission', 'prediction', 'error']]\n",
    "pred_errors.sort_values(by = 'error', ascending = False, inplace = True)\n",
    "pred_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_errors.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.emission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impo_df = pd.DataFrame({'feature': X.columns, 'importance': clf.feature_importances_}).set_index('feature').sort_values(by = 'importance', ascending = False)\n",
    "impo_df = impo_df[:12].sort_values(by = 'importance', ascending = True)\n",
    "impo_df.plot(kind = 'barh', figsize = (10, 10))\n",
    "plt.legend(loc = 'center right')\n",
    "plt.title('Bar chart showing feature importance', fontsize = 14)\n",
    "plt.xlabel('Features', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_eng.drop(['ID_LAT_LON_YEAR_WEEK', 'location'], axis = 1).fillna(0)\n",
    "predictions = clf.predict(test_df)\n",
    "\n",
    "# # Create a submission file\n",
    "sub_file = pd.DataFrame({'ID_LAT_LON_YEAR_WEEK': test_eng.ID_LAT_LON_YEAR_WEEK, 'emission': predictions})\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file.to_csv('BaselineSubmission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
